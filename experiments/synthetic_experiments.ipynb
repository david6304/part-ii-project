{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set working directory to project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "os.chdir(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.data_loader import load_synthetic_data\n",
    "from src.data_processing.preprocessor import preprocess_data\n",
    "from src.utils.graph_utils import get_dag \n",
    "from src.evaluation.metrics import calculate_base_performance\n",
    "\n",
    "dataset = \"asia\"\n",
    "target_node = \"dysp\"\n",
    "task = \"classification\"\n",
    "\n",
    "df = load_synthetic_data(dataset=dataset)\n",
    "train, val, test = preprocess_data(df)\n",
    "\n",
    "true_model, true_adj_matrix = get_dag(dataset)\n",
    "num_classes = df[target_node].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRaSP edge count: 7    \n",
      "GRaSP completed in: 0.07s \n"
     ]
    }
   ],
   "source": [
    "from src.models.causal_discovery.discovery_factory import CausalDiscoveryFactory\n",
    "\n",
    "factory = CausalDiscoveryFactory(method='grasp')\n",
    "\n",
    "learned_adj_matrix = factory.discover_graph(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 0 1]\n",
      "Results for XGB on asia dataset predicting dysp:\n",
      "{'accuracy': 0.8605, 'precision': 0.8636565388183053, 'recall': 0.857138696160475, 'f1': 0.8588690555228864}\n",
      "Number of differences between XGB predictions and true values: 279\n"
     ]
    }
   ],
   "source": [
    "from src.models.baselines.xgb import XGBBaseline\n",
    "\n",
    "xgb_model = XGBBaseline(target_node=target_node, task=task, num_classes=num_classes)\n",
    "xgb_model.train(train, val)\n",
    "\n",
    "xgb_preds = xgb_model.predict(test)\n",
    "print(xgb_preds)\n",
    "results = calculate_base_performance(test[target_node], xgb_preds, task=task)\n",
    "\n",
    "print(f\"Results for XGB on {dataset} dataset predicting {target_node}:\")\n",
    "print(results)\n",
    "\n",
    "num_differences = (xgb_preds != test[target_node]).sum()\n",
    "print(f\"Number of differences between XGB predictions and true values: {num_differences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.5068, Val Loss: 0.3592\n",
      "Epoch 2 - Train Loss: 0.4223, Val Loss: 0.3529\n",
      "Epoch 3 - Train Loss: 0.4180, Val Loss: 0.3493\n",
      "Epoch 9 - Train Loss: 0.4155, Val Loss: 0.3491\n",
      "Epoch 17 - Train Loss: 0.4154, Val Loss: 0.3472\n",
      "Epoch 18 - Train Loss: 0.4142, Val Loss: 0.3440\n",
      "Stopping early at epoch 28\n",
      "Results for MLP on asia dataset predicting dysp:\n",
      "{'accuracy': 0.8605, 'precision': 0.8636565388183053, 'recall': 0.857138696160475, 'f1': 0.8588690555228864}\n"
     ]
    }
   ],
   "source": [
    "from src.models.baselines.mlp import MLPBaseline\n",
    "\n",
    "mlp_model = MLPBaseline(target_node=target_node, task=task, num_classes=num_classes)\n",
    "mlp_model.train(train, val, patience=10, epochs=1000)\n",
    "\n",
    "mlp_preds = mlp_model.predict(test)\n",
    "results = calculate_base_performance(test[target_node], mlp_preds, task=task)\n",
    "\n",
    "print(f\"Results for MLP on {dataset} dataset predicting {target_node}:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tub | Task: classification | Num Classes: 2 | Parents: ['asia']\n",
      "Training lung | Task: classification | Num Classes: 2 | Parents: ['smoke']\n",
      "Training bronc | Task: classification | Num Classes: 2 | Parents: ['smoke']\n",
      "Training either | Task: classification | Num Classes: 2 | Parents: ['tub', 'lung']\n",
      "Training xray | Task: classification | Num Classes: 2 | Parents: ['either']\n",
      "Training dysp | Task: classification | Num Classes: 2 | Parents: ['bronc', 'either']\n",
      "Results for Hierarchical XGB on asia dataset predicting dysp:\n",
      "{'accuracy': 0.8605, 'precision': 0.8636565388183053, 'recall': 0.857138696160475, 'f1': 0.8588690555228864}\n"
     ]
    }
   ],
   "source": [
    "from src.models.baselines.hierarchical_xgb import HierarchicalXGB\n",
    "\n",
    "hier_model = HierarchicalXGB(graph=true_adj_matrix, target_node=target_node)\n",
    "hier_model.train(train, val)\n",
    "\n",
    "hier_preds = hier_model.predict(test)\n",
    "\n",
    "results = calculate_base_performance(test[target_node], hier_preds, task=task)\n",
    "\n",
    "print(f\"Results for Hierarchical XGB on {dataset} dataset predicting {target_node}:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.6345, Val Loss: 0.5647, Val Acc: 0.639\n",
      "Epoch 2 - Train Loss: 0.5499, Val Loss: 0.4787, Val Acc: 0.801\n",
      "Epoch 3 - Train Loss: 0.5034, Val Loss: 0.4534, Val Acc: 0.879\n",
      "Epoch 4 - Train Loss: 0.4876, Val Loss: 0.4299, Val Acc: 0.801\n",
      "Epoch 5 - Train Loss: 0.4832, Val Loss: 0.4269, Val Acc: 0.801\n",
      "Epoch 6 - Train Loss: 0.4816, Val Loss: 0.4233, Val Acc: 0.801\n",
      "Epoch 9 - Train Loss: 0.4805, Val Loss: 0.4216, Val Acc: 0.801\n",
      "Early stopping at epoch 19\n",
      "Results for GCN on asia dataset predicting dysp:\n",
      "{'accuracy': 0.791, 'precision': 0.77223539807261, 'recall': 0.7993906272670117, 'f1': 0.7781125553258825}\n"
     ]
    }
   ],
   "source": [
    "from src.models.causal_gnns.gcn import GCNBaseline\n",
    "\n",
    "gcn_model = GCNBaseline(target_node=target_node, task=task, num_classes=num_classes, adj_mat=true_adj_matrix)\n",
    "gcn_model.train(train, val, patience=10, epochs=500)\n",
    "\n",
    "gcn_preds = gcn_model.predict(test)\n",
    "results = calculate_base_performance(test[target_node], gcn_preds, task=task)\n",
    "\n",
    "print(f\"Results for GCN on {dataset} dataset predicting {target_node}:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<TabularCPD representing P(asia:2) at 0x1766464b0>, <TabularCPD representing P(bronc:2 | smoke:2) at 0x176bdc620>, <TabularCPD representing P(dysp:2 | bronc:2, either:2) at 0x176ae7800>, <TabularCPD representing P(either:2 | lung:2, tub:2) at 0x177aa8980>, <TabularCPD representing P(lung:2 | smoke:2) at 0x177154d10>, <TabularCPD representing P(smoke:2) at 0x177154ef0>, <TabularCPD representing P(tub:2 | asia:2) at 0x177107200>, <TabularCPD representing P(xray:2 | either:2) at 0x177b06840>]\n",
      "CACE on asia dataset intervening on xray: ({<src.models.baselines.xgb.XGBBaseline object at 0x16c57be00>: {0.0}, <src.models.baselines.mlp.MLPBaseline object at 0x17679c7a0>: {0.022}, <src.models.baselines.hierarchical_xgb.HierarchicalXGB object at 0x3029509e0>: {0.0}, <src.models.causal_gnns.gcn.GCNBaseline object at 0x30293a510>: {0.0}}, 0.0)\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation.metrics import calculate_cace\n",
    "\n",
    "\n",
    "print(true_model.cpds)\n",
    "\n",
    "intervention_node = \"bronc\"\n",
    "models = [xgb_model, mlp_model, hier_model, gcn_model]\n",
    "results = calculate_cace(\n",
    "    models=models,\n",
    "    data=test, \n",
    "    intervention_node=intervention_node, \n",
    "    adj_mat=true_adj_matrix,\n",
    "    cpds = true_model.cpds,\n",
    "    )\n",
    "\n",
    "print(f\"CACE on {dataset} dataset intervening on {intervention_node}: {results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "part-ii-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
